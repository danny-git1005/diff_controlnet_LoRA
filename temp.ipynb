{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb0a039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\aerial_img\\aerial_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\aerial_img\\aerial_venv\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.6 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import argparse\n",
    "import torch\n",
    "import wandb\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Diffusers 和相關函式庫\n",
    "from diffusers import ControlNetModel, StableDiffusionControlNetPipeline\n",
    "from diffusers.optimization import get_scheduler\n",
    "from accelerate import Accelerator, DistributedDataParallelKwargs # 為了 find_unused_parameters\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import LoraConfig # <-- Import LoraConfig\n",
    "from peft import get_peft_model\n",
    "from peft import PeftModel\n",
    "\n",
    "# 自訂模組 (需要你有這些檔案)\n",
    "from config import Config # 假設你的設定檔名為 config.py\n",
    "from utils.dataset import ControlNetDataset # 假設你的資料集類別在 utils/dataset.py\n",
    "\n",
    "# 環境變數設定\n",
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\" # 避免 TensorFlow OneDNN 相關警告\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7a0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ControlNet base model from lllyasviel/sd-controlnet-seg\n",
      " -> <class 'diffusers.models.controlnet.ControlNetModel'>\n",
      "conv_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "time_proj -> <class 'diffusers.models.embeddings.Timesteps'>\n",
      "time_embedding -> <class 'diffusers.models.embeddings.TimestepEmbedding'>\n",
      "time_embedding.linear_1 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "time_embedding.act -> <class 'torch.nn.modules.activation.SiLU'>\n",
      "time_embedding.linear_2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "controlnet_cond_embedding -> <class 'diffusers.models.controlnet.ControlNetConditioningEmbedding'>\n",
      "controlnet_cond_embedding.conv_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "controlnet_cond_embedding.blocks.0 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks.1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks.2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks.3 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks.4 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.blocks.5 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_cond_embedding.conv_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0 -> <class 'diffusers.models.unets.unet_2d_blocks.CrossAttnDownBlock2D'>\n",
      "down_blocks.0.attentions -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.0 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.0.attentions.0.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.attentions.0.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.attentions.0.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.0.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.attentions.1 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.0.attentions.1.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.attentions.1.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.attentions.1.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.attentions.1.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.resnets -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.resnets.0 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.0.resnets.0.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.resnets.0.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.resnets.0.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.resnets.0.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.resnets.0.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.resnets.0.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.resnets.1 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.0.resnets.1.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.resnets.1.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.resnets.1.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.0.resnets.1.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.0.resnets.1.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.0.resnets.1.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.0.downsamplers -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.0.downsamplers.0 -> <class 'diffusers.models.downsampling.Downsample2D'>\n",
      "down_blocks.0.downsamplers.0.conv -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1 -> <class 'diffusers.models.unets.unet_2d_blocks.CrossAttnDownBlock2D'>\n",
      "down_blocks.1.attentions -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.0 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.1.attentions.0.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.attentions.0.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.attentions.0.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.0.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.attentions.1 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.1.attentions.1.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.attentions.1.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.attentions.1.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.attentions.1.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.resnets -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.resnets.0 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.1.resnets.0.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.resnets.0.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.resnets.0.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.resnets.0.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.resnets.0.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.resnets.0.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.resnets.0.conv_shortcut -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.resnets.1 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.1.resnets.1.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.resnets.1.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.resnets.1.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.1.resnets.1.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.1.resnets.1.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.1.resnets.1.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.1.downsamplers -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.1.downsamplers.0 -> <class 'diffusers.models.downsampling.Downsample2D'>\n",
      "down_blocks.1.downsamplers.0.conv -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2 -> <class 'diffusers.models.unets.unet_2d_blocks.CrossAttnDownBlock2D'>\n",
      "down_blocks.2.attentions -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.0 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.2.attentions.0.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.attentions.0.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.attentions.0.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.0.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.attentions.1 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "down_blocks.2.attentions.1.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.attentions.1.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.attentions.1.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.attentions.1.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.resnets -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.resnets.0 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.2.resnets.0.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.resnets.0.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.resnets.0.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.resnets.0.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.resnets.0.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.resnets.0.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.resnets.0.conv_shortcut -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.resnets.1 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.2.resnets.1.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.resnets.1.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.resnets.1.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.2.resnets.1.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.2.resnets.1.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.2.resnets.1.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.2.downsamplers -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.2.downsamplers.0 -> <class 'diffusers.models.downsampling.Downsample2D'>\n",
      "down_blocks.2.downsamplers.0.conv -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.3 -> <class 'diffusers.models.unets.unet_2d_blocks.DownBlock2D'>\n",
      "down_blocks.3.resnets -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "down_blocks.3.resnets.0 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.3.resnets.0.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.3.resnets.0.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.3.resnets.0.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.3.resnets.0.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.3.resnets.0.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.3.resnets.0.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.3.resnets.1 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "down_blocks.3.resnets.1.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.3.resnets.1.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "down_blocks.3.resnets.1.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "down_blocks.3.resnets.1.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "down_blocks.3.resnets.1.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "down_blocks.3.resnets.1.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "controlnet_down_blocks.0 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.3 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.4 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.5 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.6 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.7 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.8 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.9 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.10 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_down_blocks.11 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "controlnet_mid_block -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block -> <class 'diffusers.models.unets.unet_2d_blocks.UNetMidBlock2DCrossAttn'>\n",
      "mid_block.attentions -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.attentions.0 -> <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>\n",
      "mid_block.attentions.0.norm -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "mid_block.attentions.0.proj_in -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block.attentions.0.transformer_blocks -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.attentions.0.transformer_blocks.0 -> <class 'diffusers.models.attention.BasicTransformerBlock'>\n",
      "mid_block.attentions.0.transformer_blocks.0.norm1 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "mid_block.attentions.0.transformer_blocks.0.norm2 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2 -> <class 'diffusers.models.attention_processor.Attention'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_q -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_k -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_v -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_out -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.to_out.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "mid_block.attentions.0.transformer_blocks.0.norm3 -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff -> <class 'diffusers.models.attention.FeedForward'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff.net -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff.net.0 -> <class 'diffusers.models.activations.GEGLU'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff.net.1 -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "mid_block.attentions.0.transformer_blocks.0.ff.net.2 -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.attentions.0.proj_out -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block.resnets -> <class 'torch.nn.modules.container.ModuleList'>\n",
      "mid_block.resnets.0 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "mid_block.resnets.0.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "mid_block.resnets.0.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block.resnets.0.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.resnets.0.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "mid_block.resnets.0.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "mid_block.resnets.0.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block.resnets.1 -> <class 'diffusers.models.resnet.ResnetBlock2D'>\n",
      "mid_block.resnets.1.norm1 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "mid_block.resnets.1.conv1 -> <class 'torch.nn.modules.conv.Conv2d'>\n",
      "mid_block.resnets.1.time_emb_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
      "mid_block.resnets.1.norm2 -> <class 'torch.nn.modules.normalization.GroupNorm'>\n",
      "mid_block.resnets.1.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
      "mid_block.resnets.1.conv2 -> <class 'torch.nn.modules.conv.Conv2d'>\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    \"\"\"解析命令行參數\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Train a ControlNet model using LoRA\")\n",
    "    parser.add_argument(\"--config\", type=str, default=\"config.py\", help=\"Path to config file\")\n",
    "    # --- 允許命令行覆蓋 Config 中的部分設定 ---\n",
    "    parser.add_argument(\"--condition_type\", type=str, choices=[\"canny\", \"depth\", \"pose\", \"seg\"], default=None,\n",
    "                        help=\"Override config: Type of condition to use (aligns with config)\")\n",
    "    parser.add_argument(\"--use_text_condition\", default=None, type=lambda x: (str(x).lower() == 'true'),\n",
    "                        help=\"Override config: Use text prompts (True/False)\")\n",
    "    # --- LoRA 參數覆蓋 ---\n",
    "    parser.add_argument(\"--use_lora\", default=None, type=lambda x: (str(x).lower() == 'true'),\n",
    "                        help=\"Override config: Use LoRA training (True/False)\")\n",
    "    parser.add_argument(\"--lora_rank\", type=int, default=None, help=\"Override config: LoRA rank\")\n",
    "    parser.add_argument(\"--lora_alpha\", type=int, default=None, help=\"Override config: LoRA alpha\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "config = Config()\n",
    "# --- 設定資料類型 ---\n",
    "weight_dtype = torch.float32\n",
    "# --- 載入 ControlNet 基礎模型 ---\n",
    "try:\n",
    "    controlnet = ControlNetModel.from_pretrained(\n",
    "        config.controlnet_model,\n",
    "        torch_dtype=weight_dtype # 使用基於 accelerator 的 dtype\n",
    "    )\n",
    "    print(f\"Loaded ControlNet base model from {config.controlnet_model}\")\n",
    "    for name, module in controlnet.named_modules():\n",
    "        print(name, \"->\", type(module))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ControlNet model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ea6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aerial_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
